#!/usr/bin/env python3
"""
Resumable Natural Instructions Runner for Customer Service
Enhanced version with checkpoint/resume functionality and robust logging
Can be interrupted and resumed from the last successful point
"""

import json
import requests
import time
import argparse
import logging
import uuid
import os
import pickle
import hashlib
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
import sys

# Configure logging with both file and console output
def setup_logging(log_file: str = None):
    """Setup comprehensive logging"""
    if log_file is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_file = f'natural_instructions_1001_nomemory_{timestamp}.log'
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - [%(name)s] %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ]
    )
    return logging.getLogger(__name__)

class ResumableNaturalRunner:
    def __init__(self, base_url: str = "http://localhost:7860", timeout: int = 60, api_key: Optional[str] = None):
        """Initialize Resumable Natural runner with checkpoint functionality."""
        self.base_url = base_url.rstrip('/')
        self.timeout = timeout
        self.api_key = api_key or os.environ.get('LANGFLOW_API_KEY')
        
        if not self.api_key:
            logger.warning("No LANGFLOW_API_KEY found. Some operations may fail.")
        
        self.session = requests.Session()
        self.session.headers.update({
            'Content-Type': 'application/json',
            'User-Agent': 'ResumableNaturalRunner/1.0'
        })
        
        if self.api_key:
            self.session.headers['x-api-key'] = self.api_key
        
        # Checkpoint management
        self.checkpoint_file = "natural_instructions_1001_nomemory_checkpoint.pkl"
        self.progress_file = "natural_instructions_1001_nomemory_progress.json"
        self.checkpoint_interval = 10  # Save checkpoint every N instructions
        
        # Statistics tracking
        self.stats = {
            'total_instructions': 0,
            'completed': 0,
            'successful': 0,
            'failed': 0,
            'skipped': 0,
            'start_time': None,
            'last_checkpoint_time': None,
            'resume_count': 0
        }
    
    def check_connection(self) -> bool:
        """Test connection to Langflow server with comprehensive checks."""
        logger.info("üîç Testing Langflow connection...")
        
        # Test basic health endpoint
        try:
            response = self.session.get(f"{self.base_url}/health", timeout=10)
            if response.status_code == 200:
                logger.info("‚úì Langflow health endpoint OK")
            else:
                logger.error(f"‚úó Langflow health endpoint returned status {response.status_code}")
                return False
        except requests.exceptions.RequestException as e:
            logger.error(f"‚úó Failed to connect to Langflow server: {e}")
            return False
        
        # Test API endpoint with a simple request
        logger.info("üß™ Testing API endpoint with simple request...")
        try:
            test_payload = {
                "input_value": "Connection test",
                "input_type": "chat",
                "output_type": "chat",
                "tweaks": {}
            }
            
            response = self.session.post(
                f"{self.base_url}/api/v1/run/{self.flow_id if hasattr(self, 'flow_id') else 'test'}",
                json=test_payload,
                timeout=30  # Longer timeout for API test
            )
            
            if response.status_code in [200, 404]:  # 404 is OK for test flow ID
                logger.info("‚úì API endpoint is responsive")
                return True
            else:
                logger.warning(f"‚ö† API endpoint returned status {response.status_code}")
                logger.warning("Will proceed anyway - this might be a flow-specific issue")
                return True  # Proceed anyway
                
        except requests.exceptions.Timeout:
            logger.error("‚úó API endpoint timed out - Langflow may be overloaded")
            logger.info("üí° Suggestion: Try increasing timeout or reducing concurrent requests")
            return False
        except requests.exceptions.RequestException as e:
            logger.error(f"‚úó API test failed: {e}")
            return False
    
    def load_checkpoint(self) -> Tuple[Dict, int]:
        """Load checkpoint data if exists"""
        checkpoint_data = {}
        start_index = 0
        
        if Path(self.checkpoint_file).exists():
            try:
                with open(self.checkpoint_file, 'rb') as f:
                    checkpoint_data = pickle.load(f)
                
                start_index = checkpoint_data.get('last_completed_index', 0) + 1
                self.stats = checkpoint_data.get('stats', self.stats)
                self.stats['resume_count'] += 1
                
                logger.info(f"üìÑ Checkpoint loaded: resuming from instruction {start_index}")
                logger.info(f"üìä Previous progress: {self.stats['completed']}/{self.stats['total_instructions']} completed")
                logger.info(f"üìä Success rate: {self.stats['successful']}/{max(self.stats['completed'], 1)*100:.1f}%")
                
            except Exception as e:
                logger.warning(f"‚ö† Failed to load checkpoint: {e}")
                logger.info("Starting from beginning...")
        else:
            logger.info("üÜï No checkpoint found, starting fresh run")
        
        return checkpoint_data, start_index
    
    def save_checkpoint(self, instruction_index: int, traces: List[Dict], additional_data: Dict = None):
        """Save checkpoint data"""
        checkpoint_data = {
            'last_completed_index': instruction_index,
            'traces': traces,
            'stats': self.stats,
            'timestamp': datetime.now().isoformat(),
            'additional_data': additional_data or {}
        }
        
        try:
            # Save binary checkpoint
            with open(self.checkpoint_file, 'wb') as f:
                pickle.dump(checkpoint_data, f)
            
            # Save human-readable progress
            progress_data = {
                'last_completed_index': instruction_index,
                'total_instructions': self.stats['total_instructions'],
                'completed': self.stats['completed'],
                'successful': self.stats['successful'],
                'failed': self.stats['failed'],
                'progress_percentage': (self.stats['completed'] / max(self.stats['total_instructions'], 1)) * 100,
                'success_rate': (self.stats['successful'] / max(self.stats['completed'], 1)) * 100,
                'timestamp': datetime.now().isoformat(),
                'resume_count': self.stats['resume_count']
            }
            
            with open(self.progress_file, 'w', encoding='utf-8') as f:
                json.dump(progress_data, f, indent=2, ensure_ascii=False)
            
            self.stats['last_checkpoint_time'] = datetime.now()
            logger.info(f"üíæ Checkpoint saved at instruction {instruction_index}")
            
        except Exception as e:
            logger.error(f"‚ùå Failed to save checkpoint: {e}")
    
    def run_single_instruction(self, instruction: Dict, flow_id: str, delay_ms: int = 500, max_retries: int = 3) -> Optional[Dict]:
        """Run a single instruction and return the trace with retry mechanism."""
        seed_id = instruction.get('seed_id', 'unknown')
        instruction_text = instruction.get('instruction', '')
        
        logger.info(f"üîÑ Processing instruction {seed_id}: {instruction_text[:100]}...")
        
        for attempt in range(max_retries):
            try:
                # Prepare the request
                payload = {
                    "input_value": instruction_text,
                    "input_type": "chat",
                    "output_type": "chat",
                    "tweaks": {}
                }
                
                # Add instruction metadata to payload
                if 'slots' in instruction:
                    payload['tweaks']['slots'] = instruction['slots']
                
                # Use longer timeout for natural instructions (they might be complex)
                request_timeout = max(self.timeout, 45)  # At least 45 seconds
                
                if attempt > 0:
                    logger.info(f"üîÑ Retry attempt {attempt + 1}/{max_retries} for {seed_id}")
                
                # Make the request
                response = self.session.post(
                    f"{self.base_url}/api/v1/run/{flow_id}",
                    json=payload,
                    timeout=request_timeout
                )
                
                if response.status_code == 200:
                    result = response.json()
                    
                    # Create comprehensive trace
                    trace = {
                        'seed_id': seed_id,
                        'instruction': instruction_text,
                        'original_instruction_data': instruction,
                        'timestamp': datetime.now().isoformat(),
                        'flow_id': flow_id,
                        'response_status': 'success',
                        'langflow_response': result,
                        'execution_time_ms': response.elapsed.total_seconds() * 1000,
                        'category': instruction.get('category', 'unknown'),
                        'intent': instruction.get('intent', 'unknown'),
                        'retry_count': attempt
                    }
                    
                    # Extract tools used if available
                    if 'outputs' in result:
                        for output in result['outputs']:
                            if 'results' in output and 'message' in output['results']:
                                message = output['results']['message']
                                if 'tools_used' in message:
                                    trace['tools_used'] = message['tools_used']
                                if 'tool_calls' in message:
                                    trace['tool_calls'] = message['tool_calls']
                    
                    logger.info(f"‚úÖ Successfully processed {seed_id}" + (f" (attempt {attempt + 1})" if attempt > 0 else ""))
                    return trace
                    
                else:
                    # Non-200 status code
                    if attempt < max_retries - 1:
                        logger.warning(f"‚ö†Ô∏è Request failed for {seed_id}: HTTP {response.status_code}, retrying...")
                        time.sleep(2 ** attempt)  # Exponential backoff
                        continue
                    else:
                        logger.error(f"‚ùå Request failed for {seed_id}: HTTP {response.status_code} (final attempt)")
                        logger.error(f"Response: {response.text[:500]}")
                        return {
                            'seed_id': seed_id,
                            'instruction': instruction_text,
                            'original_instruction_data': instruction,
                            'timestamp': datetime.now().isoformat(),
                            'response_status': 'error',
                            'error_code': response.status_code,
                            'error_message': response.text[:500],
                            'category': instruction.get('category', 'unknown'),
                            'intent': instruction.get('intent', 'unknown'),
                            'retry_count': attempt + 1
                        }
            
            except requests.exceptions.Timeout:
                if attempt < max_retries - 1:
                    logger.warning(f"‚è∞ Timeout for instruction {seed_id} (attempt {attempt + 1}), retrying...")
                    time.sleep(5)  # Wait before retry
                    continue
                else:
                    logger.error(f"‚è∞ Timeout for instruction {seed_id} (final attempt)")
                    return {
                        'seed_id': seed_id,
                        'instruction': instruction_text,
                        'original_instruction_data': instruction,
                        'timestamp': datetime.now().isoformat(),
                        'response_status': 'timeout',
                        'error_message': f'Request timeout after {max_retries} attempts',
                        'category': instruction.get('category', 'unknown'),
                        'retry_count': attempt + 1
                    }
            
            except Exception as e:
                if attempt < max_retries - 1:
                    logger.warning(f"üí• Exception for instruction {seed_id} (attempt {attempt + 1}): {e}, retrying...")
                    time.sleep(2)
                    continue
                else:
                    logger.error(f"üí• Exception for instruction {seed_id} (final attempt): {e}")
                    return {
                        'seed_id': seed_id,
                        'instruction': instruction_text,
                        'original_instruction_data': instruction,
                        'timestamp': datetime.now().isoformat(),
                        'response_status': 'exception',
                        'error_message': str(e),
                        'category': instruction.get('category', 'unknown'),
                        'retry_count': attempt + 1
                    }
        
        # Apply delay after successful request or final failure
        if delay_ms > 0:
            time.sleep(delay_ms / 1000.0)
        
        # This should never be reached, but just in case
        return None
    
    def run_instructions(self, instructions_file: str, flow_id: str, output_file: str, 
                        delay_ms: int = 500, resume: bool = True) -> int:
        """Run all instructions with checkpoint/resume support."""
        
        # Load instructions
        try:
            instructions = []
            with open(instructions_file, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    if line:
                        try:
                            instructions.append(json.loads(line))
                        except json.JSONDecodeError as e:
                            logger.error(f"Invalid JSON on line {line_num}: {e}")
                            continue
            
            if not instructions:
                logger.error(f"No valid instructions found in {instructions_file}")
                return 3
            
            self.stats['total_instructions'] = len(instructions)
            logger.info(f"üìö Loaded {len(instructions)} instructions from {instructions_file}")
            
        except FileNotFoundError:
            logger.error(f"Instructions file not found: {instructions_file}")
            return 3
        except Exception as e:
            logger.error(f"Error loading instructions: {e}")
            return 3
        
        # Load checkpoint if resuming
        checkpoint_data = {}
        start_index = 0
        traces = []
        
        if resume:
            checkpoint_data, start_index = self.load_checkpoint()
            traces = checkpoint_data.get('traces', [])
        
        # Set start time if not resuming
        if self.stats['start_time'] is None:
            self.stats['start_time'] = datetime.now()
        
        # Store flow_id for connection test
        self.flow_id = flow_id
        
        # Test connection
        if not self.check_connection():
            logger.error("Cannot connect to Langflow server")
            return 2
        
        logger.info(f"üöÄ Starting natural instructions execution from instruction {start_index}")
        logger.info(f"üìä Progress: {start_index}/{len(instructions)} ({start_index/len(instructions)*100:.1f}%)")
        
        # Process instructions
        try:
            for i, instruction in enumerate(instructions[start_index:], start_index):
                logger.info(f"\n{'='*60}")
                logger.info(f"üìç Processing {i+1}/{len(instructions)} (Resume count: {self.stats['resume_count']})")
                
                trace = self.run_single_instruction(instruction, flow_id, delay_ms)
                
                if trace:
                    traces.append(trace)
                    self.stats['completed'] += 1
                    
                    if trace.get('response_status') == 'success':
                        self.stats['successful'] += 1
                    else:
                        self.stats['failed'] += 1
                else:
                    self.stats['skipped'] += 1
                
                # Save checkpoint periodically
                if (i + 1) % self.checkpoint_interval == 0:
                    self.save_checkpoint(i, traces, {'flow_id': flow_id})
                
                # Progress reporting
                progress = (i + 1) / len(instructions) * 100
                success_rate = self.stats['successful'] / max(self.stats['completed'], 1) * 100
                logger.info(f"üìä Progress: {progress:.1f}% | Success: {success_rate:.1f}% | Completed: {self.stats['completed']}")
        
        except KeyboardInterrupt:
            logger.info("\n‚ö†Ô∏è Interrupted by user - saving checkpoint...")
            self.save_checkpoint(i, traces, {'flow_id': flow_id, 'interrupted': True})
            logger.info("üíæ Checkpoint saved. Use --resume to continue later.")
            return 130  # Standard exit code for Ctrl+C
        
        except Exception as e:
            logger.error(f"üí• Unexpected error: {e}")
            self.save_checkpoint(i, traces, {'flow_id': flow_id, 'error': str(e)})
            return 1
        
        # Save final results
        try:
            # Save traces
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(traces, f, indent=2, ensure_ascii=False)
            
            # Save statistics
            stats_file = output_file.replace('.json', '_stats.json')
            final_stats = self.stats.copy()
            
            # Ensure all datetime objects are properly serialized
            end_time = datetime.now()
            final_stats['end_time'] = end_time.isoformat()
            
            # Calculate total duration safely
            start_time = final_stats['start_time']
            if isinstance(start_time, datetime):
                start_time_str = start_time.isoformat()
            else:
                start_time_str = str(start_time)
            
            final_stats['start_time'] = start_time_str
            
            try:
                if isinstance(start_time, datetime):
                    total_duration = end_time - start_time
                else:
                    # Parse from string if needed
                    start_dt = datetime.fromisoformat(start_time_str.replace('Z', '+00:00'))
                    total_duration = end_time - start_dt
                final_stats['total_duration'] = str(total_duration)
            except Exception as e:
                logger.warning(f"Could not calculate total_duration: {e}")
                final_stats['total_duration'] = "unknown"
            
            # Ensure all numeric values are proper types
            for key in ['successful', 'failed', 'completed', 'skipped', 'total_instructions', 'resume_count']:
                if key in final_stats:
                    final_stats[key] = int(final_stats[key])
            
            with open(stats_file, 'w', encoding='utf-8') as f:
                json.dump(final_stats, f, indent=2, ensure_ascii=False)
            
            # Clean up checkpoint files
            for file in [self.checkpoint_file, self.progress_file]:
                if Path(file).exists():
                    Path(file).unlink()
            
            logger.info(f"\nüéâ EXECUTION COMPLETED!")
            logger.info(f"üìÑ Traces saved to: {output_file}")
            logger.info(f"üìä Statistics saved to: {stats_file}")
            logger.info(f"üìà Final stats: {self.stats['successful']}/{self.stats['completed']} successful ({self.stats['successful']/max(self.stats['completed'], 1)*100:.1f}%)")
            
            return 0 if self.stats['successful'] >= self.stats['failed'] else 1
            
        except Exception as e:
            logger.error(f"Error saving results: {e}")
            return 1

def main():
    """Main execution function with argument parsing."""
    parser = argparse.ArgumentParser(description='Resumable Natural Instructions Runner for Customer Service')
    parser.add_argument('--flow-id', required=True, help='Langflow flow ID')
    parser.add_argument('--instructions', default='natural_instructions.jsonl', 
                       help='Instructions JSONL file')
    parser.add_argument('--output', default='traces_natural_resumable.json', 
                       help='Output traces JSON file')
    parser.add_argument('--delay-ms', type=int, default=500, 
                       help='Delay between requests in milliseconds')
    parser.add_argument('--timeout', type=int, default=30, 
                       help='Request timeout in seconds')
    parser.add_argument('--base-url', default='http://localhost:7860', 
                       help='Langflow base URL')
    parser.add_argument('--no-resume', action='store_true', 
                       help='Start fresh (ignore checkpoint)')
    parser.add_argument('--log-file', help='Custom log file name')
    
    args = parser.parse_args()
    
    # Setup logging
    global logger
    logger = setup_logging(args.log_file)
    
    logger.info("üöÄ RESUMABLE NATURAL INSTRUCTIONS RUNNER STARTED")
    logger.info(f"üìã Configuration:")
    logger.info(f"   Flow ID: {args.flow_id}")
    logger.info(f"   Instructions: {args.instructions}")
    logger.info(f"   Output: {args.output}")
    logger.info(f"   Base URL: {args.base_url}")
    logger.info(f"   Resume: {not args.no_resume}")
    
    # Create runner and execute
    runner = ResumableNaturalRunner(
        base_url=args.base_url,
        timeout=args.timeout
    )
    
    exit_code = runner.run_instructions(
        instructions_file=args.instructions,
        flow_id=args.flow_id,
        output_file=args.output,
        delay_ms=args.delay_ms,
        resume=not args.no_resume
    )
    
    logger.info(f"üèÅ Execution finished with exit code: {exit_code}")
    sys.exit(exit_code)

if __name__ == "__main__":
    main()
